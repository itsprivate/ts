{
  "approved_at_utc": null,
  "subreddit": "askphilosophy",
  "selftext": "One could respond to my question in itself, but here is the picture I have in mind: philosophical positions hang together in a **web of belief**, whose nodes are the positions and whose edges (or perhaps \"edges\" shaped like neural connections, since inferences often have multiple premises) are inferences or arguments or reasons. Each node has a degree of plausibility or probability and each edge has a degree of strength.\n\n**Philosophical problems** are tensions or incoherences or contradictions within the web. The aim of philosophy, then, would be a **reflective equilibrium of the web of belief**, or a reassignment of plausibilities assigned to the various positions such that these incoherences are resolved and explanatory coherence is maximised. Arguably, this explicates the aim of philosophy according to Sellars (\"to understand how things...hang together\"), since explanations are accounts that provide understanding. Like science, the Duhem-Quine thesis holds for philosophy too: it's impossible to test philosophical theories in isolation, but only as a corporate body with auxiliary assumptions.\n\nThe **visual animation** I have in mind of the reflective equilibrium is something like a [3Blue1Brown video on neural network learning algorithms](https://youtube.com/watch?v=aircAruvnKk) but instead of adjusting the strength of connections (presumably we can't do so here since the strength of an inference is fixed) we adjust strength of node (i.e. plausibility of a position). And instead of being linear, it is holistic like Quine's web of belief. And instead of optimising towards matching some supervised learning data, we optimise towards explanatory coherence or perhaps towards the **epistemic standards that the web of belief legislates upon itself (I am evoking themes from pragmatism or naturalism or Kuhn or Hegel or Quine or Sellars or Kant or self-correcting, self-improving AI; immanence, not transcendence)**.",
  "author_fullname": "t2_8vkasb9q",
  "saved": false,
  "mod_reason_title": null,
  "gilded": 0,
  "clicked": false,
  "title": "Since we usually can't claim any philosophical position to be true with certainty, is all philosophy basically finding the optimal set of plausibilities to assign philosophical positions such that explanatory coherence is maximised?",
  "link_flair_richtext": [],
  "subreddit_name_prefixed": "r/askphilosophy",
  "hidden": false,
  "pwls": 6,
  "link_flair_css_class": null,
  "downs": 0,
  "top_awarded_type": null,
  "hide_score": false,
  "name": "t3_mdkhn4",
  "quarantine": false,
  "link_flair_text_color": "dark",
  "upvote_ratio": 0.96,
  "author_flair_background_color": null,
  "subreddit_type": "public",
  "ups": 104,
  "total_awards_received": 1,
  "media_embed": {},
  "author_flair_template_id": null,
  "is_original_content": false,
  "user_reports": [],
  "secure_media": null,
  "is_reddit_media_domain": false,
  "is_meta": false,
  "category": null,
  "secure_media_embed": {},
  "link_flair_text": null,
  "can_mod_post": false,
  "score": 104,
  "approved_by": null,
  "author_premium": false,
  "thumbnail": "",
  "edited": 1616762120,
  "author_flair_css_class": null,
  "author_flair_richtext": [],
  "gildings": {},
  "content_categories": null,
  "is_self": true,
  "mod_note": null,
  "created": 1616778219,
  "link_flair_type": "text",
  "wls": 6,
  "removed_by_category": null,
  "banned_by": null,
  "author_flair_type": "text",
  "domain": "self.askphilosophy",
  "allow_live_comments": false,
  "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>One could respond to my question in itself, but here is the picture I have in mind: philosophical positions hang together in a <strong>web of belief</strong>, whose nodes are the positions and whose edges (or perhaps &quot;edges&quot; shaped like neural connections, since inferences often have multiple premises) are inferences or arguments or reasons. Each node has a degree of plausibility or probability and each edge has a degree of strength.</p>\n\n<p><strong>Philosophical problems</strong> are tensions or incoherences or contradictions within the web. The aim of philosophy, then, would be a <strong>reflective equilibrium of the web of belief</strong>, or a reassignment of plausibilities assigned to the various positions such that these incoherences are resolved and explanatory coherence is maximised. Arguably, this explicates the aim of philosophy according to Sellars (&quot;to understand how things...hang together&quot;), since explanations are accounts that provide understanding. Like science, the Duhem-Quine thesis holds for philosophy too: it&#39;s impossible to test philosophical theories in isolation, but only as a corporate body with auxiliary assumptions.</p>\n\n<p>The <strong>visual animation</strong> I have in mind of the reflective equilibrium is something like a <a href=\"https://youtube.com/watch?v=aircAruvnKk\">3Blue1Brown video on neural network learning algorithms</a> but instead of adjusting the strength of connections (presumably we can&#39;t do so here since the strength of an inference is fixed) we adjust strength of node (i.e. plausibility of a position). And instead of being linear, it is holistic like Quine&#39;s web of belief. And instead of optimising towards matching some supervised learning data, we optimise towards explanatory coherence or perhaps towards the <strong>epistemic standards that the web of belief legislates upon itself (I am evoking themes from pragmatism or naturalism or Kuhn or Hegel or Quine or Sellars or Kant or self-correcting, self-improving AI; immanence, not transcendence)</strong>.</p>\n</div><!-- SC_ON -->",
  "likes": null,
  "suggested_sort": "confidence",
  "banned_at_utc": null,
  "view_count": null,
  "archived": false,
  "no_follow": false,
  "is_crosspostable": false,
  "pinned": false,
  "over_18": false,
  "awarders": [],
  "media_only": false,
  "can_gild": false,
  "spoiler": false,
  "locked": false,
  "author_flair_text": null,
  "treatment_tags": [],
  "visited": false,
  "removed_by": null,
  "num_reports": null,
  "distinguished": null,
  "subreddit_id": "t5_2sc5r",
  "mod_reason_by": null,
  "removal_reason": null,
  "link_flair_background_color": "",
  "id": "mdkhn4",
  "is_robot_indexable": true,
  "report_reasons": null,
  "author": "rescherach",
  "discussion_type": null,
  "num_comments": 17,
  "send_replies": true,
  "whitelist_status": "all_ads",
  "contest_mode": false,
  "mod_reports": [],
  "author_patreon_flair": false,
  "author_flair_text_color": null,
  "permalink": "/r/askphilosophy/comments/mdkhn4/since_we_usually_cant_claim_any_philosophical/",
  "parent_whitelist_status": "all_ads",
  "stickied": false,
  "url": "https://www.reddit.com/r/askphilosophy/comments/mdkhn4/since_we_usually_cant_claim_any_philosophical/",
  "subreddit_subscribers": 173815,
  "created_utc": 1616778313,
  "num_crossposts": 0,
  "media": null,
  "is_video": false,
  "original_created_utc": 1616749419,
  "the_new_excerpt": "One could respond to my question in itself, but here is the picture I have in\nmind: philosophical positions hang together in a web of belief, whose nodes are\nthe positions and whose edges (or perhaps \"edges\" shaped like neural\nconnections, since inferences often have multiple premises) are…",
  "localize": [
    {
      "locale": "zh",
      "the_new_excerpt": "可以回答我的问题本身，但这是我的图片中的图片。\n思想：哲学立场串联成一张信仰之网，其结点是......。\n的位置，其边缘(或者可能是 \"边缘\"，形状像神经系统的 \"边缘\")。\n联系，因为推论往往有多个前提）是......",
      "title": "既然我们通常不能肯定地宣称任何哲学立场都是真实的，那么所有的哲学基本上都是在寻找一组最佳的可信性来分配哲学立场，从而使解释的一致性最大化？"
    },
    {
      "locale": "zh-Hant",
      "the_new_excerpt": "可以回答我的問題本身，但這是我的圖片中的圖片。\n思想：哲學立場串聯成一張信仰之網，其結點是......。\n的位置，其邊緣(或者可能是 \"邊緣\"，形狀像神經系統的 \"邊緣\")。\n聯繫，因爲推論往往有多個前提）是......",
      "title": "既然我們通常不能肯定地宣稱任何哲學立場都是真實的，那麼所有的哲學基本上都是在尋找一組最佳的可信性來分配哲學立場，從而使解釋的一致性最大化？"
    }
  ]
}