{
  "approved_at_utc": null,
  "subreddit": "askphilosophy",
  "selftext": "Let's imagine a future where a company can create a perfect simulated reality powered by a strong AI; a person comes and asks to be the leader of a totalitarian regime perpetrating a genocide, or a child abuser, or something of the like. \n\nWould it be ethical to let them do this things inside the computer, given that for them it's indistinguishable from real life? Most can argue that as it means no harm for others, and the rest of humanity won't even know what's going on within that personal, private simulation, it should be allowed due to individual liberty. But two main questions come to my mind:\n\na) The people inside the simulation are in some way _real_ because they are being simulated? Have an existence of their own? Can they just be abused without hesitation?\n\nb) If we accept that the 'NPC' inside the simulation are just reflections of the connected person's mind, could we infer that they are harming themselves in some way by commiting such crimes, although just virtually? Should such _self-harm_ be allowed?\n\nLooking forward to know your thoughts.",
  "author_fullname": "t2_9snv4otj",
  "saved": false,
  "mod_reason_title": null,
  "gilded": 0,
  "clicked": false,
  "title": "In a hypothetical scenario where people could legally pay to live in a custom-made simulated reality, indistinguishable from the real world, and unaware of it being a simulation once they are connected to the computer; would it be ethical to let them commit horrible crimes within such simulation?",
  "link_flair_richtext": [],
  "subreddit_name_prefixed": "r/askphilosophy",
  "hidden": false,
  "pwls": 6,
  "link_flair_css_class": null,
  "downs": 0,
  "top_awarded_type": null,
  "hide_score": false,
  "name": "t3_mv7fri",
  "quarantine": false,
  "link_flair_text_color": "dark",
  "upvote_ratio": 0.98,
  "author_flair_background_color": null,
  "subreddit_type": "public",
  "ups": 102,
  "total_awards_received": 0,
  "media_embed": {},
  "author_flair_template_id": null,
  "is_original_content": false,
  "user_reports": [],
  "secure_media": null,
  "is_reddit_media_domain": false,
  "is_meta": false,
  "category": null,
  "secure_media_embed": {},
  "link_flair_text": null,
  "can_mod_post": false,
  "score": 102,
  "approved_by": null,
  "author_premium": false,
  "thumbnail": "",
  "edited": 1619011887,
  "author_flair_css_class": null,
  "author_flair_richtext": [],
  "gildings": {},
  "content_categories": null,
  "is_self": true,
  "mod_note": null,
  "created": 1619005019,
  "link_flair_type": "text",
  "wls": 6,
  "removed_by_category": null,
  "banned_by": null,
  "author_flair_type": "text",
  "domain": "self.askphilosophy",
  "allow_live_comments": false,
  "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Let&#39;s imagine a future where a company can create a perfect simulated reality powered by a strong AI; a person comes and asks to be the leader of a totalitarian regime perpetrating a genocide, or a child abuser, or something of the like. </p>\n\n<p>Would it be ethical to let them do this things inside the computer, given that for them it&#39;s indistinguishable from real life? Most can argue that as it means no harm for others, and the rest of humanity won&#39;t even know what&#39;s going on within that personal, private simulation, it should be allowed due to individual liberty. But two main questions come to my mind:</p>\n\n<p>a) The people inside the simulation are in some way <em>real</em> because they are being simulated? Have an existence of their own? Can they just be abused without hesitation?</p>\n\n<p>b) If we accept that the &#39;NPC&#39; inside the simulation are just reflections of the connected person&#39;s mind, could we infer that they are harming themselves in some way by commiting such crimes, although just virtually? Should such <em>self-harm</em> be allowed?</p>\n\n<p>Looking forward to know your thoughts.</p>\n</div><!-- SC_ON -->",
  "likes": null,
  "suggested_sort": "confidence",
  "banned_at_utc": null,
  "view_count": null,
  "archived": false,
  "no_follow": false,
  "is_crosspostable": false,
  "pinned": false,
  "over_18": false,
  "awarders": [],
  "media_only": false,
  "can_gild": false,
  "spoiler": false,
  "locked": false,
  "author_flair_text": null,
  "treatment_tags": [],
  "visited": false,
  "removed_by": null,
  "num_reports": null,
  "distinguished": null,
  "subreddit_id": "t5_2sc5r",
  "mod_reason_by": null,
  "removal_reason": null,
  "link_flair_background_color": "",
  "id": "mv7fri",
  "is_robot_indexable": true,
  "report_reasons": null,
  "author": "gatoplanta",
  "discussion_type": null,
  "num_comments": 23,
  "send_replies": true,
  "whitelist_status": "all_ads",
  "contest_mode": false,
  "mod_reports": [],
  "author_patreon_flair": false,
  "author_flair_text_color": null,
  "permalink": "/r/askphilosophy/comments/mv7fri/in_a_hypothetical_scenario_where_people_could/",
  "parent_whitelist_status": "all_ads",
  "stickied": false,
  "url": "https://www.reddit.com/r/askphilosophy/comments/mv7fri/in_a_hypothetical_scenario_where_people_could/",
  "subreddit_subscribers": 176660,
  "created_utc": 1619020533,
  "num_crossposts": 0,
  "media": null,
  "is_video": false,
  "original_created_utc": 1618976219,
  "the_new_excerpt": "Let's imagine a future where a company can create a perfect simulated reality\npowered by a strong AI; a person comes and asks to be the leader of a\ntotalitarian regime perpetrating a genocide, or a child abuser, or something of\nthe like.\n\nWould it be ethical to let them do this things inside theâ€¦"
}